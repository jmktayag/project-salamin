# User Testing Protocol Guide

## Overview

This protocol guide outlines the structured approach for conducting user testing sessions during Salamin's walk phase validation. It covers both moderated and unmoderated testing approaches, session structure, and follow-up procedures.

## Testing Approach Framework

### Week 1-2: Moderated Testing (5-8 participants)
**Format:** Live, moderated sessions via video call  
**Duration:** 45 minutes total (30 min testing + 15 min interview)  
**Goal:** Deep qualitative insights and immediate feedback  

### Week 3-4: Unmoderated Testing (7-10 additional participants)
**Format:** Self-guided with follow-up survey  
**Duration:** 30 minutes testing + 10 minutes survey  
**Goal:** Broader validation and behavioral data  

## Pre-Session Preparation

### Moderator Checklist (24 hours before)
- [ ] Send calendar invite with Zoom/Meet link
- [ ] Email participant with consent form and preparation instructions
- [ ] Test recording setup (screen + audio)
- [ ] Prepare observation notes template
- [ ] Review participant background (career stage, experience level)
- [ ] Set up backup communication method (phone/text)

### Participant Preparation Email Template
```
Subject: Tomorrow's Interview Practice Testing - Quick Prep (5 min read)

Hi [Name],

Excited to speak with you tomorrow at [Time]! This will be fun and helpful - you'll get to try our interview practice tool and I'll gather your feedback to make it better.

WHAT TO EXPECT (45 minutes total):
• 5 min: Quick intro and consent
• 30 min: You try our interview practice platform
• 10 min: Your feedback and thoughts

WHAT YOU NEED:
• Computer with Chrome or Edge browser (best audio support)
• Quiet space for 45 minutes
• Optional: Headphones for better audio

ZOOM LINK: [Link]
Meeting ID: [ID]
Backup phone: [Number]

No prep needed - just bring your curiosity! You'll be helping improve a tool that other job seekers will use.

Questions? Just reply to this email.

Looking forward to it!
[Name]
```

## Moderated Session Structure

### Phase 1: Introduction (5 minutes)

#### Welcome and Context
"Hi [Name], thanks for joining me today! I'm excited to get your feedback on our interview practice platform. Before we start, a few quick things:

- This is about testing our tool, not testing you
- There are no right or wrong answers
- Please think out loud as you go
- Feel free to be brutally honest - that helps us most
- Any questions before we begin?"

#### Consent and Recording
- [ ] Confirm consent form received and understood
- [ ] Get verbal permission for recording
- [ ] Start screen recording
- [ ] Begin session notes

#### Quick Background (2 minutes)
"Tell me briefly about your current job search situation:
- Are you actively interviewing?
- When was your last interview?
- What's your biggest interview challenge?"

### Phase 2: Platform Testing (30 minutes)

#### Testing Instructions
"I'm going to send you a link to our platform. I want you to imagine you're preparing for a [specific role] interview and use this tool as you naturally would. Please think out loud as you go - tell me what you're thinking, what's confusing, what you like, etc."

#### Observation Focus Areas
- [ ] **Initial reaction:** First impressions, clarity of purpose
- [ ] **Navigation:** How easily they find their way around
- [ ] **Configuration:** Can they set up their interview type/role?
- [ ] **Question engagement:** Do they understand what's being asked?
- [ ] **Response method:** Do they type, speak, or both?
- [ ] **Feature discovery:** Do they find TTS, microphone, etc.?
- [ ] **Feedback reaction:** How do they respond to AI feedback?
- [ ] **Completion:** Do they finish the full interview?

#### Gentle Prompts (use sparingly)
- "What are you thinking right now?"
- "What would you expect to happen next?"
- "How does this compare to your expectations?"
- "What's going through your mind?"

#### Technical Issue Protocol
If technical issues arise:
1. Note the issue and context
2. Help them resolve it quickly
3. Ask: "How frustrating was that on a scale of 1-10?"
4. Continue with session
5. Follow up on impact in feedback phase

### Phase 3: Feedback Interview (10 minutes)

#### Overall Experience
- "Describe your overall experience in one word."
- "What was the main value you got from this?"
- "How did this compare to your expectations?"

#### Specific Features
- "Which features did you find most/least valuable?"
- "Did anything confuse you or feel unnecessary?"
- "What would make this more useful for your interview prep?"

#### Comparison and Context
- "How does this compare to other interview prep you've done?"
- "In what situation would you use this?"
- "Would you recommend this to a friend? Why/why not?"

#### Priority Improvements
- "If you could change one thing, what would it be?"
- "What would make you more likely to use this regularly?"
- "Any features missing that you expected?"

## Unmoderated Testing Protocol

### Self-Guided Session Setup

#### Participant Instructions Email
```
Subject: Your Interview Practice Testing Session - Start When Ready

Hi [Name],

Thanks for agreeing to test our interview practice platform! This is completely self-guided - start whenever works for you in the next 3 days.

INSTRUCTIONS:
1. Go to: [Platform URL]
2. Use the platform as if you're preparing for a real interview
3. Try to complete a full interview session (about 30 minutes)
4. Fill out this quick feedback survey: [Survey Link]

WHAT TO KEEP IN MIND:
• This is about testing our tool, not testing you
• No right or wrong answers
• Try features that interest you (voice input, audio playback, etc.)
• Be honest in your feedback - it helps us improve

TECHNICAL SUPPORT:
If you run into any issues, email [email] or text [phone].

We'll follow up in a few days to see how it went!

[Name]
```

#### Follow-up Timeline
- **Day 1:** Send session instructions
- **Day 3:** Gentle reminder if no activity detected
- **Day 5:** Follow-up email with survey link if not completed
- **Day 7:** Final reminder and offer of alternative time

### Unmoderated Session Monitoring

#### Automated Tracking (if implemented)
- Session start/completion times
- Drop-off points in the flow
- Feature usage patterns
- Technical errors encountered

#### Manual Check-ins
- Daily review of completed sessions
- Quick outreach for any obvious technical issues
- Personal thank you for completed sessions

## Data Collection and Analysis

### Session Notes Template

#### Participant Info
- **Name:** [Name]
- **Date/Time:** [DateTime]
- **Session Type:** Moderated/Unmoderated
- **Background:** [Career stage, interview experience]

#### Behavioral Observations
- **First impressions:** Initial reaction to platform
- **Navigation patterns:** How they moved through the interface
- **Feature adoption:** What they used vs. ignored
- **Confusion points:** Where they got stuck or frustrated
- **Positive reactions:** What excited or impressed them
- **Completion:** Did they finish? Where did they stop?

#### Technical Issues
- **Problems encountered:** Specific errors or failures
- **User impact:** How much it affected their experience
- **Resolution:** How it was resolved
- **User reaction:** Frustration level, likelihood to continue

#### Verbatim Quotes
- **Value statements:** How they described the benefit
- **Confusion:** Exact words when they were confused
- **Suggestions:** Specific improvement ideas
- **Comparisons:** How they related it to other tools

### Post-Session Analysis

#### Individual Session Review (within 24 hours)
- [ ] Review recording and notes
- [ ] Identify key insights and quotes
- [ ] Note any critical technical issues
- [ ] Send personal thank you with next steps

#### Weekly Compilation
- [ ] Aggregate completion rates and drop-off points
- [ ] Identify common patterns in feedback
- [ ] Prioritize technical issues by frequency
- [ ] Compile improvement suggestions by theme

## Quality Assurance

### Session Quality Indicators
- **Engagement:** Participant actively used features and provided thoughtful feedback
- **Completion:** Reached end of interview and provided survey response
- **Authenticity:** Genuine, honest reactions rather than trying to be helpful
- **Detail:** Specific, actionable feedback rather than generic praise

### Red Flags to Watch For
- **Overly positive:** Seems like they're trying to be nice rather than honest
- **Rushed:** Going too quickly without engaging with features
- **Technical dominance:** Session derailed by technical issues
- **Misaligned:** Using tool in way that doesn't match intended use case

## Follow-up and Relationship Building

### Immediate Follow-up (within 24 hours)

#### Thank You Email Template
```
Subject: Thank you for testing our interview platform!

Hi [Name],

Thank you so much for taking the time to test our interview practice platform yesterday! Your feedback was incredibly valuable and will directly influence how we improve the tool.

KEY TAKEAWAYS FROM YOUR SESSION:
• [Specific insight from their feedback]
• [Feature they found most valuable]
• [Improvement suggestion they made]

WHAT'S NEXT:
• We're implementing several improvements based on your feedback
• You'll be first to know when new features are available
• We'll share how your input influenced our development

If you have any additional thoughts or questions, please don't hesitate to reach out.

Thanks again for helping make interview preparation better for job seekers!

Best,
[Name]
```

### Long-term Engagement

#### Monthly Updates
- Share product improvements made based on their feedback
- Invite to test new features before general release
- Provide relevant career resources and interview tips

#### Success Stories
- Follow up on their job search progress
- Request permission to share success stories (anonymized)
- Offer references or LinkedIn recommendations

#### Community Building
- Invite to private LinkedIn group for early testers
- Connect them with other job seekers in similar situations
- Facilitate peer learning and networking opportunities

## Contingency Plans

### Technical Issues During Session
1. **Document the issue:** Exact error, browser, timing
2. **Try quick fix:** Refresh, different browser, restart
3. **Offer alternatives:** Continue on phone, reschedule, async testing
4. **Maintain focus:** Don't let technical issues dominate the session
5. **Follow up:** Ensure issue gets resolved for future participants

### Participant No-Shows
1. **Wait 10 minutes** beyond scheduled time
2. **Send friendly text/email** asking if they need to reschedule
3. **Offer flexible alternatives** (different time, async testing)
4. **Don't take it personally** - people have busy lives
5. **Keep spot open** for other interested participants

### Low Response Rates
1. **Review recruitment messaging** - is value proposition clear?
2. **Increase incentives** if budget allows
3. **Expand recruitment channels** to different communities
4. **Simplify participation** - reduce time commitment or complexity
5. **Personal outreach** - more individualized, less mass messaging

This protocol ensures consistent, high-quality data collection while maintaining a positive experience for participants that builds long-term relationships with potential users.